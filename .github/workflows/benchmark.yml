# yamllint disable rule:truthy
---
name: Benchmark Models

on:
  pull_request:
    types: [opened, synchronize]
  push:
    branches: [main]

# yamllint enable rule:truthy

jobs:
  detect-changes:
    if: github.actor != 'github-actions[bot]'
    runs-on: ubuntu-latest
    outputs:
      should_run: ${{ steps.models.outputs.should_run }}
      model_chunks: ${{ steps.models.outputs.model_chunks }}
      models: ${{ steps.models.outputs.models }}
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0
          ref: ${{ github.head_ref || github.ref_name }}
      - name: Fetch base reference
        if: github.event_name == 'pull_request'
        run: git fetch origin ${{ github.base_ref }} --depth=1
      - name: Determine benchmark models
        id: models
        env:
          DEFAULT_MODELS: cycle_dual
          CHUNK_SIZE: '2'
        run: |
          python <<'PY'
          import json
          import os
          import subprocess
          from pathlib import Path

          def has_ref(ref: str) -> bool:
              return subprocess.run(
                  ["git", "rev-parse", "--verify", ref],
                  stdout=subprocess.DEVNULL,
                  stderr=subprocess.DEVNULL,
                  check=False,
              ).returncode == 0

          base_ref = os.environ.get("GITHUB_BASE_REF")
          compare_ref = f"origin/{base_ref}" if base_ref else "origin/main"
          if not has_ref(compare_ref):
              compare_ref = "HEAD^"

          diff_args = ["git", "diff", "--name-only"]
          if has_ref(compare_ref):
              diff_args.append(f"{compare_ref}...HEAD")

          result = subprocess.run(
              diff_args,
              check=False,
              stdout=subprocess.PIPE,
              text=True,
          )

          changed_files: list[str] = []
          for line in result.stdout.splitlines():
              line = line.strip()
              if line:
                  changed_files.append(line)

          changed_models = set()
          for path in changed_files:
              if (
                  not path.startswith("xtylearner/models/")
                  or not path.endswith(".py")
              ):
                  continue
              name = Path(path).stem
              if name.endswith("_model"):
                  name = name[: -len("_model")]
              changed_models.add(name)

          default_models = [
              model.strip()
              for model in os.environ.get("DEFAULT_MODELS", "").split(",")
              if model.strip()
          ]
          if changed_models:
              selected = sorted(set(default_models) | changed_models)
          else:
              selected = default_models

          if not selected:
              selected = ["cycle_dual"]

          chunk_size = max(1, int(os.environ.get("CHUNK_SIZE", "1")))
          chunks: list[list[str]] = []
          for index in range(0, len(selected), chunk_size):
              chunks.append(selected[index : index + chunk_size])

          output_path = Path(os.environ["GITHUB_OUTPUT"])
          chunk_output = ["should_run=true", f"models={','.join(selected)}"]
          chunk_strings = [",".join(chunk) for chunk in chunks]
          chunk_output.append("model_chunks=" + json.dumps(chunk_strings))
          output_text = "\n".join(chunk_output) + "\n"
          output_path.write_text(output_text, encoding="utf-8")

          print("Selected models:", ", ".join(selected))
          for index, chunk in enumerate(chunks):
              print(f"Chunk {index}: {', '.join(chunk)}")
          PY

  benchmark:
    needs: detect-changes
    if: needs.detect-changes.outputs.should_run == 'true'
    runs-on: ubuntu-latest
    env:
      PYTHON_VERSION: '3.12'
    strategy:
      fail-fast: false
      matrix:
        model_chunk: >-
          ${{ fromJson(needs.detect-changes.outputs.model_chunks) }}
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0
          ref: ${{ github.head_ref || github.ref_name }}
      - uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'  # yamllint disable-line rule:truthy
          cache-dependency-path: |
            asv.conf.json
            requirements.txt
      - name: Install ASV tooling
        run: |
          python -m pip install --upgrade pip
          python -m pip install asv
      - name: Compute ASV cache key
        id: asv-cache
        run: |
          python <<'PY'
          import hashlib
          import os
          from pathlib import Path

          paths = [Path('asv.conf.json'), Path('requirements.txt')]
          digest = hashlib.sha256()
          for path in paths:
              if path.exists():
                  digest.update(path.read_bytes())

          output = Path(os.environ['GITHUB_OUTPUT'])
          with output.open('a', encoding='utf-8') as handle:
              handle.write(f"fingerprint={digest.hexdigest()}\n")
              handle.write("prefix=asv-env-ubuntu-latest-py3.12\n")
          PY
      - name: Restore cached ASV environments
        id: cache-asv
        uses: actions/cache@v4
        with:
          path: .asv/env
          key: ${{ steps.asv-cache.outputs.prefix }}-${{ steps.asv-cache.outputs.fingerprint }}
          restore-keys: |
            ${{ steps.asv-cache.outputs.prefix }}-
      - name: Run ASV benchmarks
        env:
          BENCHMARK_MODELS: ${{ matrix.model_chunk }}
        run: |
          set -euo pipefail
          asv machine --yes --machine github-actions
          COMMIT_HASH=$(git rev-parse HEAD)
          if git rev-parse "${COMMIT_HASH}^" >/dev/null 2>&1; then
            COMMIT_SPEC="${COMMIT_HASH}^!"
          else
            COMMIT_SPEC="$COMMIT_HASH"
          fi
          echo "Running benchmarks for commit: $COMMIT_HASH"
          echo "Model chunk: ${BENCHMARK_MODELS:-<default>}"
          asv run "$COMMIT_SPEC" \
            --machine github-actions \
            --config asv.conf.json \
            --show-stderr
          if ! find .asv/results/github-actions -maxdepth 1 \
              -name "*.json" -not -name "machine.json" -print -quit; then
            echo "No benchmark result files were produced"
            exit 1
          fi
          asv publish --config asv.conf.json --html-dir .asv/html
      - name: Prepare artifact name
        id: artifact
        env:
          MODEL_CHUNK: ${{ matrix.model_chunk }}
        run: |
          SAFE_NAME=${MODEL_CHUNK:-default}
          SAFE_NAME=$(printf '%s' "$SAFE_NAME" | tr ' ,/' '---')
          SAFE_NAME=$(printf '%s' "$SAFE_NAME" | tr -c 'A-Za-z0-9-_' '_')
          echo "name=asv-results-$SAFE_NAME" >> "$GITHUB_OUTPUT"
      - name: Upload benchmark artifacts
        uses: actions/upload-artifact@v4
        with:
          name: ${{ steps.artifact.outputs.name }}
          path: |
            .asv/results/github-actions
            .asv/html
