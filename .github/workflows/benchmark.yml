name: Benchmark Models

on:
  pull_request:
    types: [opened, synchronize]
  push:
    branches: [main]

jobs:
  detect-changes:
    if: github.actor != 'github-actions[bot]'
    runs-on: ubuntu-latest
    outputs:
      benchmark_strategy: ${{ steps.changes.outputs.strategy }}
      changed_models: ${{ steps.changes.outputs.models }}
      should_run: ${{ steps.changes.outputs.should_run }}
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0
          ref: ${{ github.head_ref || github.ref_name }}
      - name: Detect changes and determine benchmark strategy
        id: changes
        run: |
          set -euo pipefail
          if [ "${{ github.event_name }}" = "pull_request" ]; then
            BASE_SHA="${{ github.event.pull_request.base.sha }}"
            git fetch --no-tags --depth=1 origin "$BASE_SHA"
            CHANGED_FILES=$(git diff --name-only "$BASE_SHA"...HEAD -- 'xtylearner/models/*.py')

            if [ -z "$CHANGED_FILES" ]; then
              echo "No model files changed, running core models only"
              echo "strategy=core" >> "$GITHUB_OUTPUT"
              echo "models=jsbf,eg_ddi,cevae_m" >> "$GITHUB_OUTPUT"
            else
              echo "Model files changed, running selective benchmarks"
              printf '%s\n' "$CHANGED_FILES"
              export CHANGED_FILES
              MODELS=$(python - <<'PY'
import os
from pathlib import Path

core = ["jsbf", "eg_ddi", "cevae_m"]
models = []
for relative in os.environ.get("CHANGED_FILES", "").splitlines():
    name = Path(relative).stem
    if name.endswith("_model"):
        name = name[:-6]
    if name and name not in models:
        models.append(name)
for item in core:
    if item not in models:
        models.append(item)
print(",".join(models))
PY
)
              echo "models=$MODELS" >> "$GITHUB_OUTPUT"
              echo "strategy=selective" >> "$GITHUB_OUTPUT"
            fi
            echo "should_run=true" >> "$GITHUB_OUTPUT"
          else
            echo "Full benchmark on push"
            echo "strategy=full" >> "$GITHUB_OUTPUT"
            echo "models=" >> "$GITHUB_OUTPUT"
            echo "should_run=true" >> "$GITHUB_OUTPUT"
          fi

  benchmark:
    needs: detect-changes
    if: needs.detect-changes.outputs.should_run == 'true'
    runs-on: ubuntu-latest
    permissions:
      contents: write
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0
          ref: ${{ github.head_ref || github.ref_name }}
      - uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'
          cache-dependency-path: |
            pyproject.toml
            requirements.txt
      - name: Install ASV
        run: |
          python -m pip install --upgrade pip
          pip install asv
      - name: Record ASV machine info
        run: asv machine --yes --machine github-actions
      - name: Prepare benchmark filters
        id: filters
        env:
          BENCHMARK_MODELS: ${{ needs.detect-changes.outputs.changed_models }}
        run: |
          python - <<'PY'
import json
import os

models = [m.strip() for m in os.environ.get("BENCHMARK_MODELS", "").split(",") if m.strip()]
with open(os.environ["GITHUB_OUTPUT"], "w") as fh:
    fh.write(f"models={json.dumps(models)}\n")
PY
      - name: Run ASV benchmarks
        env:
          MODEL_FILTERS: ${{ steps.filters.outputs.models }}
        run: |
          python - <<'PY'
import json
import os
import subprocess
import sys

filters = os.environ.get("MODEL_FILTERS")
args = [
    "asv",
    "run",
    "--machine",
    "github-actions",
    "--repo",
    ".",
    "--steps",
    "1",
    "HEAD^!",
]
if filters:
    for model in json.loads(filters):
        args.extend(["--parameter", f"model={model}"])
print("Running:", " ".join(args))
sys.exit(subprocess.call(args))
PY
      - name: Generate HTML reports
        run: |
          if ls .asv/results/github-actions/*.json 2>/dev/null | grep -v machine.json; then
            asv publish --html-dir .asv/html
          else
            echo "No benchmark data files found, creating placeholder HTML"
            mkdir -p .asv/html
            echo "<html><body><h1>No benchmark data available yet</h1></body></html>" > .asv/html/index.html
          fi
      - name: Deploy to GitHub Pages
        uses: peaceiris/actions-gh-pages@v3
        if: github.ref == 'refs/heads/main'
        with:
          github_token: ${{ secrets.GITHUB_TOKEN }}
          publish_dir: .asv/html
          force_orphan: true
      - name: Upload benchmark results
        uses: actions/upload-artifact@v4
        with:
          name: benchmark-results
          path: .asv/results
