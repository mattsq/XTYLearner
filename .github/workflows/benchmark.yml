name: Benchmark Models

on:
  pull_request:
    types: [opened, synchronize]
  push:
    branches: [main]

jobs:
  detect-changes:
    if: github.actor != 'github-actions[bot]'
    runs-on: ubuntu-latest
    outputs:
      benchmark_strategy: ${{ steps.changes.outputs.strategy }}
      changed_models: ${{ steps.changes.outputs.models }}
      should_run: ${{ steps.changes.outputs.should_run }}
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0
          ref: ${{ github.head_ref || github.ref_name }}
      - name: Detect changes and determine benchmark strategy
        id: changes
        run: |
          if [ "${{ github.event_name }}" = "pull_request" ]; then
            # Get changed files in models directory
            CHANGED_FILES=$(git diff --name-only origin/${{ github.base_ref }}...HEAD | grep "xtylearner/models/.*\.py$" || true)
            
            if [ -z "$CHANGED_FILES" ]; then
              echo "No model files changed, running core models only"
              echo "strategy=core" >> $GITHUB_OUTPUT
              echo "models=jsbf,eg_ddi,cevae_m" >> $GITHUB_OUTPUT
              echo "should_run=true" >> $GITHUB_OUTPUT
            else
              echo "Model files changed, running selective benchmarks"
              echo "strategy=selective" >> $GITHUB_OUTPUT
              # Extract model names from file paths and add core models
              MODELS=$(echo "$CHANGED_FILES" | sed 's|xtylearner/models/||g' | sed 's|_model\.py||g' | sed 's|\.py||g' | tr '\n' ',' | sed 's/,$//')
              echo "models=$MODELS,jsbf,eg_ddi,cevae_m" >> $GITHUB_OUTPUT
              echo "should_run=true" >> $GITHUB_OUTPUT
              echo "Changed model files: $CHANGED_FILES"
              echo "Will benchmark models: $MODELS,jsbf,eg_ddi,cevae_m"
            fi
          else
            # Full benchmark on main branch pushes - use core models for now to debug
            echo "strategy=core" >> $GITHUB_OUTPUT
            echo "models=jsbf,eg_ddi,cevae_m" >> $GITHUB_OUTPUT
            echo "should_run=true" >> $GITHUB_OUTPUT
          fi

  benchmark:
    needs: detect-changes
    if: needs.detect-changes.outputs.should_run == 'true'
    runs-on: ubuntu-latest
    permissions:
      contents: write
    strategy:
      matrix:
        chunk: ${{ fromJson(needs.detect-changes.outputs.benchmark_strategy == 'parallel' && '[0, 1, 2, 3]' || '[0]') }}
      fail-fast: false
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0
          ref: ${{ github.head_ref || github.ref_name }}
      - name: Set up git references for ASV
        run: |
          git branch -a
          # Ensure main branch exists locally for ASV
          git checkout -B main origin/main 2>/dev/null || true
          # Go back to the working branch
          git checkout ${{ github.head_ref || github.ref_name }} 2>/dev/null || git checkout HEAD
      - uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'
          cache-dependency-path: |
            pyproject.toml
            requirements.txt
      - name: Restore or save venv
        id: cache-venv
        uses: actions/cache@v4
        with:
          path: .venv
          key: venv-${{ runner.os }}-py3.11-${{ hashFiles('requirements.txt') }}

      - name: Ensure .venv on PATH
        if: steps.cache-venv.outputs.cache-hit == 'true'
        run: echo "$GITHUB_WORKSPACE/.venv/bin" >> "$GITHUB_PATH"
      - name: Build venv if needed
        if: steps.cache-venv.outputs.cache-hit != 'true'
        env:
          PIP_EXTRA_INDEX_URL: https://download.pytorch.org/whl/cpu
        run: |
          python -m venv .venv
          . .venv/bin/activate
          pip install -r requirements.txt
          echo "$VIRTUAL_ENV/bin" >> $GITHUB_PATH
      - name: Install package and ASV
        env:
          PIP_EXTRA_INDEX_URL: https://download.pytorch.org/whl/cpu
        run: |
          source .venv/bin/activate
          python -m pip install --upgrade pip
          pip install torch==2.3.0 --index-url https://download.pytorch.org/whl/cpu
          pip install -e .
          pip install asv
      - name: Configure ASV machine
        run: |
          . .venv/bin/activate
          asv machine --yes --machine github-actions
      - name: Run ASV benchmarks
        env:
          BENCHMARK_MODELS: ${{ needs.detect-changes.outputs.changed_models }}
          MODEL_CHUNK_INDEX: ${{ matrix.chunk }}
          MODEL_CHUNK_TOTAL: ${{ needs.detect-changes.outputs.benchmark_strategy == 'parallel' && '4' || '1' }}
        run: |
          set +e  # Disable exit on error for this step
          . .venv/bin/activate
          
          # Always use the real commit hash - never modify it
          COMMIT_HASH=$(git rev-parse HEAD)
          
          echo "Running benchmarks for commit: $COMMIT_HASH"
          echo "Benchmark strategy: ${{ needs.detect-changes.outputs.benchmark_strategy }}"
          echo "Changed models: $BENCHMARK_MODELS"
          echo "Chunk: $MODEL_CHUNK_INDEX/$MODEL_CHUNK_TOTAL"
          
          # For parallel execution, use temporary result directory to avoid conflicts
          if [ "${{ needs.detect-changes.outputs.benchmark_strategy }}" = "parallel" ]; then
            # Create temporary results directory for this chunk
            TEMP_RESULTS_DIR=".asv/results-chunk-${{ matrix.chunk }}"
            mkdir -p "$TEMP_RESULTS_DIR/github-actions"
            
            # Run ASV with temporary results directory
            echo "Running ASV with chunk-specific results directory..."
            asv run --machine github-actions -E existing --python same --results-dir "$TEMP_RESULTS_DIR"
            
            # Copy machine.json if it doesn't exist in main results
            if [ -f "$TEMP_RESULTS_DIR/github-actions/machine.json" ] && [ ! -f ".asv/results/github-actions/machine.json" ]; then
              mkdir -p .asv/results/github-actions
              cp "$TEMP_RESULTS_DIR/github-actions/machine.json" ".asv/results/github-actions/machine.json"
            fi
          else
            # Non-parallel execution - use standard ASV run with full debugging
            echo "=== DEBUGGING ASV EXECUTION ==="
            echo "Working directory: $(pwd)"
            echo "Python executable: $(which python)"
            echo "ASV version: $(asv --version)"
            echo "ASV configuration:"
            cat asv.conf.json
            echo ""
            echo "Benchmark files:"
            find benchmarks -name "*.py" -exec echo "File: {}" \; -exec head -5 {} \;
            echo ""
            echo "Current git commit: $(git rev-parse HEAD)"
            echo "Git status:"
            git status --porcelain
            echo ""
            echo "Environment variables:"
            env | grep -E "(BENCHMARK|MODEL|CHUNK)" || echo "No benchmark env vars"
            echo ""
            echo "=== TEST 2: MANUAL BENCHMARK EXECUTION ==="
            echo "Testing direct benchmark execution outside ASV..."
            python -c "
            import sys
            sys.path.insert(0, '.')
            from examples.benchmark_models import _run_single
            import time
            
            print('Direct benchmark test:')
            start = time.time()
            try:
                result = _run_single(('synthetic', 'cycle_dual'))
                end = time.time()
                print(f'SUCCESS: {end-start:.2f}s - {result}')
            except Exception as e:
                end = time.time()
                print(f'FAILED: {end-start:.2f}s - {e}')
            "
            MANUAL_EXIT_CODE=$?
            echo "Manual benchmark exit code: $MANUAL_EXIT_CODE"
            echo ""
            echo "=== TEST 3: ASV ENVIRONMENT AND DEPENDENCY CHECKS ==="
            echo "ASV machine info:"
            asv machine --machine github-actions --yes || echo "Machine setup failed"
            echo ""
            echo "ASV environment details:"
            python -c "
            import sys
            print(f'Python path: {sys.path}')
            print(f'Python executable: {sys.executable}')
            try:
                import xtylearner
                print(f'XTYLearner import: SUCCESS')
                from xtylearner.models import get_model
                model = get_model('cycle_dual', d_x=2, d_y=1, k=2)
                print(f'Model creation: SUCCESS - {type(model)}')
            except Exception as e:
                print(f'XTYLearner test: FAILED - {e}')
            "
            echo ""
            echo "ASV benchmark discovery:"
            asv list || echo "Benchmark discovery failed"
            echo ""
            echo "ASV dry run test:"
            asv run --dry-run --quick --machine github-actions -E existing --python same || echo "Dry run failed"
            echo ""
            echo "=== RUNNING ASV WITH VERBOSE OUTPUT ==="
            asv run --machine github-actions -E existing --python same --verbose --show-stderr
            ASV_EXIT_CODE=$?
            echo "ASV exit code: $ASV_EXIT_CODE"
            echo ""
            echo "=== TEST 4: FILE PERMISSIONS AND RESULT WRITING ==="
            echo "Testing result directory permissions:"
            ls -la .asv/
            ls -la .asv/results/
            ls -la .asv/results/github-actions/ || echo "github-actions dir missing"
            echo ""
            echo "Testing file creation in results directory:"
            echo '{"test": "write permissions"}' > .asv/results/test-write.json
            if [ -f ".asv/results/test-write.json" ]; then
              echo "SUCCESS: Can write to results directory"
              rm .asv/results/test-write.json
            else
              echo "FAILED: Cannot write to results directory"
            fi
            echo ""
            echo "Disk space and filesystem info:"
            df -h .
            echo ""
            echo "=== POST-ASV DEBUGGING ==="
            echo "Results directory after ASV:"
            find .asv/results -type f -name "*.json" | while read file; do
              echo "File: $file ($(wc -c < "$file") bytes)"
              echo "Content preview:"
              head -3 "$file" || echo "Cannot read file"
              echo "---"
            done
            echo ""
            echo "All .asv directory contents:"
            find .asv -type f | head -20
          fi
          
          # Show what was created
          echo "ASV results directory contents:"
          if [ "${{ needs.detect-changes.outputs.benchmark_strategy }}" = "parallel" ]; then
            ls -la ".asv/results-chunk-${{ matrix.chunk }}/github-actions/" || echo "No chunk results directory found"
          else
            ls -la .asv/results/github-actions/ || echo "No ASV results directory found"
          fi
          
          set -e  # Re-enable exit on error
      - name: Generate HTML reports
        run: |
          . .venv/bin/activate
          # Check what results exist before publishing
          echo "=== ASV Results before publish ==="
          find .asv/results -name "*.json" -exec echo "File: {}" \; -exec wc -l {} \;
          # Check git branches available
          echo "=== Git branches ==="
          git branch -a
          # Generate HTML (skip if no benchmark data exists)
          if ls .asv/results/github-actions/*.json 2>/dev/null | grep -v machine.json; then
            echo "Found benchmark data files, generating HTML..."
            asv publish --html-dir .asv/html
          else
            echo "No benchmark data files found, creating minimal HTML structure..."
            mkdir -p .asv/html
            echo "<html><body><h1>No benchmark data available yet</h1></body></html>" > .asv/html/index.html
          fi
          # Check what HTML was generated
          echo "=== HTML files generated ==="
          ls -la .asv/html/ || echo "No HTML directory created"
      # Deploy only for non-parallel execution (single chunk)
      - name: Deploy single chunk results to GitHub Pages
        uses: peaceiris/actions-gh-pages@v3
        if: github.ref == 'refs/heads/main' && needs.detect-changes.outputs.benchmark_strategy != 'parallel'
        with:
          github_token: ${{ secrets.GITHUB_TOKEN }}
          publish_dir: .asv/html
          force_orphan: true
      - name: Commit benchmark results
        if: github.event_name == 'pull_request'
        run: |
          git config user.name "github-actions"
          git config user.email "github-actions@github.com"
          git add .asv/results
          if ! git diff --cached --quiet; then
            git commit -m "Update ASV benchmark results"
            git push origin HEAD:${{ github.head_ref }}
          fi
      - name: Upload benchmark results
        uses: actions/upload-artifact@v4
        with:
          name: benchmark-results-chunk-${{ matrix.chunk }}
          path: ${{ needs.detect-changes.outputs.benchmark_strategy == 'parallel' && format('.asv/results-chunk-{0}', matrix.chunk) || '.asv/results' }}

  merge-results:
    needs: [detect-changes, benchmark]
    if: needs.detect-changes.outputs.benchmark_strategy == 'parallel'
    runs-on: ubuntu-latest
    permissions:
      contents: write
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0
          ref: ${{ github.head_ref || github.ref_name }}
      - name: Download all benchmark results
        uses: actions/download-artifact@v4
        with:
          pattern: benchmark-results-chunk-*
          path: benchmark-chunks
          merge-multiple: true
      - name: Set up git references for ASV
        run: |
          git branch -a
          git checkout -B main origin/main 2>/dev/null || true
          git checkout ${{ github.head_ref || github.ref_name }} 2>/dev/null || git checkout HEAD
      - uses: actions/setup-python@v5
        with:
          python-version: '3.11'
      - name: Install ASV
        run: |
          python -m pip install asv
      - name: Install Python dependencies for merging
        run: |
          python -m pip install --upgrade pip
      - name: Merge benchmark results
        run: |
          # Get the real commit hash
          REAL_COMMIT_HASH=$(git rev-parse HEAD)
          echo "Real commit hash: $REAL_COMMIT_HASH"
          
          # Create output directory
          mkdir -p .asv/results/github-actions
          
          # Copy machine.json from any chunk (they should be identical)
          echo "=== Copying machine.json ==="
          find benchmark-chunks -name "machine.json" -type f | head -1 | while read -r machine_file; do
            if [ -n "$machine_file" ]; then
              echo "Copying machine.json from $machine_file"
              cp "$machine_file" ".asv/results/github-actions/machine.json"
            fi
          done
          
          # Find all chunk result directories
          CHUNK_DIRS=""
          echo "Looking for chunk directories in benchmark-chunks/"
          find benchmark-chunks -name "results-chunk-*" -type d | while read -r chunk_dir; do
            echo "Found chunk directory: $chunk_dir"
          done
          
          # Try multiple possible artifact structures
          for chunk_path in benchmark-chunks/.asv/results-chunk-*/ benchmark-chunks/results-chunk-*/; do
            if [ -d "$chunk_path" ]; then
              CHUNK_DIRS="$CHUNK_DIRS $chunk_path"
              echo "Added chunk directory: $chunk_path"
            fi
          done
          
          if [ -n "$CHUNK_DIRS" ]; then
            echo "=== Merging chunk results using Python script ==="
            echo "Chunk directories: $CHUNK_DIRS"
            python scripts/merge_asv_results.py \
              --chunk-dirs $CHUNK_DIRS \
              --output-dir .asv/results \
              --commit-hash "$REAL_COMMIT_HASH"
          else
            echo "No chunk directories found!"
            echo "Available benchmark-chunks contents:"
            find benchmark-chunks -type f -name "*.json" | head -10
          fi
          
          # Show final merged results
          echo "=== Final ASV Results ==="
          ls -la .asv/results/github-actions/
          echo "=== Result file contents check ==="
          find .asv/results/github-actions -name "*.json" -not -name "machine.json" | while read -r file; do
            echo "File: $file"
            echo "Commit hash in file: $(jq -r '.commit_hash' "$file" 2>/dev/null || echo 'N/A')"
            echo "Benchmarks in file: $(jq -r '.results | keys[]' "$file" 2>/dev/null | wc -l || echo 'N/A')"
          done
          
          # Generate combined HTML
          if ls .asv/results/github-actions/*.json 2>/dev/null | grep -v machine.json; then
            echo "Generating combined HTML from merged results..."
            asv publish --html-dir .asv/html
          else
            echo "No benchmark data files found after merge"
            mkdir -p .asv/html
            echo "<html><body><h1>No benchmark data available</h1></body></html>" > .asv/html/index.html
          fi
      - name: Deploy merged results to GitHub Pages
        uses: peaceiris/actions-gh-pages@v3
        if: github.ref == 'refs/heads/main'
        with:
          github_token: ${{ secrets.GITHUB_TOKEN }}
          publish_dir: .asv/html
          force_orphan: true
